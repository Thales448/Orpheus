{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE CODE NO Parallelism or fancy logging\n",
    "\"\"\"\n",
    "This is the script to get all the option.ticks and populate the dataabse correctly for future use\n",
    "1. initiates tickers in the options.tickers table and returns unique ticker id called sid\n",
    "2. constructs all the expiration dates that exist and inserts them into options.expirations by sid\n",
    "3. retieves available dates of data for every expiration in the sid\n",
    "4. For every day available populates unique option contract into options.contracts by sid\n",
    "5. for every contract_id populates a timeseriesdb with 1 minute date \n",
    "6. Logs avgg.contrctacts/expiration, avg. ticks/contract, total ticks, total exp_dates, total_contracts \n",
    "\"\"\"\n",
    "import Orpheus\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "log_filename = os.path.join(os.getcwd(), 'scriptlogg.log')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info(\"Logging is set up.\")\n",
    "\n",
    "def SUPERDOWNLOAD_OPTION_OHLC(ticker):\n",
    "    datacollector = Orpheus.Charts().datacollector\n",
    "    charts = Orpheus.Charts()\n",
    "#retrieves tickers unique Id or creates one in options.tickers\n",
    "    sid = charts.conn.get_or_create_root(ticker)\n",
    "    logging.info(f\"ðŸ†” Working on SID: {sid} for ticker: {ticker}\")   \n",
    "\n",
    "# Collects expirationdates and inserts it to options.expiration\n",
    "    expiry_list = datacollector.collect_expiration_dates({'root':  ticker})\n",
    "    charts.conn.insert_expiration_dates(sid,[datetime.datetime.strptime(str(date), \"%Y%m%d\").date() for date in expiry_list])\n",
    "    exp_list=[date for date in expiry_list if date>20170101]\n",
    "    total_expiration_dates = len(exp_list)\n",
    "    logging.info(f\"ðŸ“… Found {len(expiry_list)} expiration dates, Only collecting for {total_expiration_dates} after filtering\")\n",
    "\n",
    "# Collects dates available and downloads tick data for option contract.\n",
    "    current_expiration=1\n",
    "    for exp_date in exp_list:\n",
    "        params={'root': ticker, 'exp':exp_date, 'sec': 'option', 'rec':'ohlc'}\n",
    "        dates_theta = datacollector.collect_theta_list(paramaters=params)\n",
    "        dates_avail= [date for date in dates_theta if date>20160101]\n",
    "        params = {'selector': \"ohlc\", 'exp': exp_date, 'start_date': dates_avail[0], 'end_date': dates_avail[len(dates_avail) -1 ] , 'root': ticker, 'ivl': 60000}\n",
    "        data_in_expiration = datacollector.theta_bulk_options(params)\n",
    "\n",
    "# THIS BLOCK IS PER EXPIRATION DATE!!! ther can be 450+ expiration dates per ticker plan accordingly\n",
    "        if data_in_expiration:\n",
    "            current_contract = 1\n",
    "            total_contracts = len(data_in_expiration[0]['response'])\n",
    "            exp_chain_data=[]\n",
    "            contracts_in_expiry_tick_list = []\n",
    "            \n",
    "    # THIS BLOCK IS PER CONTRACT!! there can be 80+ contracts per expiration date    \n",
    "            for entry in data_in_expiration[0]['response']:\n",
    "                contract = (entry['contract'])\n",
    "                contract['']\n",
    "                ticks = entry['ticks']\n",
    "                date_base = datetime.datetime.strptime(str(ticks[-1][-1]), \"%Y%m%d\")\n",
    "                contract_id = charts.conn.get_or_create_contract(contract)\n",
    "\n",
    "        # THIS BLOCK IS PER CONTRACT MINUTE! there can be 400000+ ticks per contract plan accordingly.        \n",
    "                for tick in ticks:\n",
    "                    ms_of_day = tick[0]\n",
    "                    time = date_base + datetime.timedelta(milliseconds=ms_of_day)\n",
    "                    contracts_in_expiry_tick_list.append((time, contract_id, *tick))\n",
    "                \n",
    "                current_contract+=1\n",
    "        current_expiration+=1\n",
    "        #charts.conn.insert_option_data(contracts_in_expiry_tick_list, theta=True)\n",
    "    \n",
    "\n",
    "SUPERDOWNLOAD_OPTION_OHLC('NVDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Orpheus'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpx\u001b[39;00m  \u001b[38;5;66;03m# install via pip install httpx\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mOrpheus\u001b[39;00m\n\u001b[32m      4\u001b[39m conn = Orpheus.Charts().conn\n\u001b[32m      6\u001b[39m BASE_URL = \u001b[33m\"\u001b[39m\u001b[33mhttp://127.0.0.1:25510/v2\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# all endpoints use this URL base\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'Orpheus'"
     ]
    }
   ],
   "source": [
    "import httpx  # install via pip install httpx\n",
    "import Orpheus\n",
    "\n",
    "conn = Orpheus.Charts().conn\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:25510/v2\"  # all endpoints use this URL base\n",
    "url = BASE_URL + '/hist/stock/eod'\n",
    "\n",
    "tick_dickt = {}\n",
    "tuples = conn.insert_new_command(\"SELECT * FROM tickers\")\n",
    "\n",
    "for root in [t[0] for t in tuples]:\n",
    "  try:\n",
    "    params = {\n",
    "      'root': root,\n",
    "      'start_date': '20250422',\n",
    "      'end_date': '20250429',\n",
    "    }\n",
    "\n",
    "    response = httpx.get(url, params=params, timeout=60)  \n",
    "    res = response.json()\n",
    "    total = 0\n",
    "    for r in res['response']:\n",
    "        total += r[6]\n",
    "    avg_vol = int(total / len(res['response']))\n",
    "    print(f\"Average volume for {root} is {avg_vol}\")\n",
    "    tick_dickt[root] = avg_vol\n",
    "  except Exception as e:\n",
    "    print(f\"Error for {root}: {e}\")\n",
    "    continue\n",
    "\n",
    "# sample_dict = {'a': 5, 'b': 2, 'c': 9, 'd': 1, 'e': 5, 'f': 6}\n",
    "# sorted_dict = dict(sorted(sample_dict.items(), key=lambda item: item[1]))\n",
    "\n",
    "print(tick_dickt)\n",
    "import Orpheus\n",
    "\n",
    "conn = Orpheus.Charts().conn\n",
    "conn.copy_csv(\"options.quotes\", '/home/r/QuantLab/externalDisk/AAPL_2024_quotes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               open      high       low     close    volume\n",
      "time                                                                       \n",
      "2025-01-02 09:40:00+00:00  586.2700  586.8400  586.1400  586.4849    176752\n",
      "2025-01-02 09:40:00+00:00  245.2300  245.7599  245.0800  245.7500    284116\n",
      "2025-01-02 09:41:00+00:00  586.5150  586.8600  586.3687  586.5940    111028\n",
      "2025-01-02 09:41:00+00:00  245.7426  245.7426  245.1600  245.2250    252975\n",
      "2025-01-02 09:42:00+00:00  245.2500  245.6700  244.8000  245.5550    441448\n",
      "...                             ...       ...       ...       ...       ...\n",
      "2025-06-03 15:58:00+00:00  203.3800  203.4300  203.3322  203.3750    279702\n",
      "2025-06-03 15:58:00+00:00  596.4450  596.4950  596.3200  596.4000    780023\n",
      "2025-06-03 16:30:00+00:00  201.3500  203.7700  200.9550  203.2700  46381567\n",
      "2025-06-03 16:30:00+00:00  592.3400  597.0800  591.8500  596.0900  63606204\n",
      "2025-06-03 20:30:00+00:00  592.3400  597.0800  591.8500  596.0900  63606204\n",
      "\n",
      "[81410 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/r/Workspace')  # Not the Orpheus folder, its parent!\n",
    "from Orpheus.Charts import DataCollector\n",
    "from Orpheus.Charts import DatabaseConnection\n",
    "from Orpheus.Charts import config\n",
    "import pandas as pd\n",
    "\n",
    "db = DatabaseConnection()\n",
    "dataC= DataCollector(db, config)\n",
    "columns =['time', 'open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "#spy = dataC.get_stocks_minute('SPY')\n",
    "spy = db.get_stock_data('SPY', resolution='minute', start_time='2025-01-01')\n",
    "spy_df = pd.DataFrame(spy, columns=columns)\n",
    "spy_df.set_index('time', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(spy_df[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r/Workspace/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
